import pandas as pd
import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import os
import time
import json
import numpy as np
from typing import Optional, Dict, Any, Tuple
from google.colab import userdata
from google.colab import files
import time
from google.api_core import exceptions # éœ€è¦åŒ¯å…¥ç‰¹å®šçš„éŒ¯èª¤é¡å‹
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

# --- å…¨åŸŸå¸¸æ•¸è¨­å®š ---
# MODEL_NAME = 'gemini-1.5-flash-latest'
# MODEL_NAME = 'gemini-2.0-flash'
MODEL_NAME = 'gemini-2.5-flash-lite-preview-06-17'
# MODEL_NAME = 'gemini-2.0-flash-lite'
# MODEL_NAME = 'gemini-2.5-flash'
# MODEL_NAME = 'gemini-2.5-pro'
DELAY_SECONDS = 6
initial_data = None
# --- æª”æ¡ˆè·¯å¾‘è¨­å®š ---
# æ‚¨çš„åŸå§‹è³‡æ–™é›†æª”æ¡ˆåç¨±
ORIGINAL_DATA_FILE = 'phishing_dataset_expansion_1.csv'
# ç¨‹å¼æœƒè‡ªå‹•å»ºç«‹ä¸¦æ›´æ–°é€™å€‹æª”æ¡ˆä¾†å„²å­˜é€²åº¦
IN_PROGRESS_FILE = 'phishing_dataset_expansion_1_Gemini.csv'



def setup_gemini() -> Optional[genai.GenerativeModel]:
    """
    è¨­å®š Google API é‡‘é‘°ä¸¦åˆå§‹åŒ– Gemini æ¨¡å‹ã€‚
    Returns:
        æˆåŠŸæ™‚è¿”å›åˆå§‹åŒ–çš„æ¨¡å‹ç‰©ä»¶ï¼Œå¤±æ•—æ™‚è¿”å› Noneã€‚
    """
    print("æ­£åœ¨è¨­å®š Gemini API...")
    # --- è¨­å®š API é‡‘é‘° (Colab ç‰ˆæœ¬) ---
    try:
        # å¾ Colab çš„å¯†é‘°ç®¡ç†å™¨ä¸­è®€å– API é‡‘é‘°
        api_key = userdata.get('GOOGLE_API_KEY')
        genai.configure(api_key=api_key)
        generation_config=genai.GenerationConfig(
            temperature=0.4,
            response_mime_type="application/json"
        )
        model = genai.GenerativeModel(
            MODEL_NAME,
            generation_config=generation_config)
        print("âœ… Gemini API è¨­å®šæˆåŠŸï¼")
        return model
    except userdata.SecretNotFoundError:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åç‚º 'GOOGLE_API_KEY' çš„å¯†é‘°ã€‚è«‹æª¢æŸ¥å·¦å´ã€Œé‘°åŒ™ã€åœ–ç¤ºä¸­çš„è¨­å®šã€‚")
        exit()
    except Exception as e:
        print(f"è¨­å®šæ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")
        exit()

def fetch_webpage_text(url: str) -> Tuple[Optional[str], str]:
    """
    çˆ¬å–æŒ‡å®š URL çš„ç´”æ–‡å­—å…§å®¹ï¼Œå„ªå…ˆä½¿ç”¨éœæ…‹çˆ¬å–ï¼Œè‹¥å…§å®¹ç‚ºç©ºå‰‡åˆ‡æ›è‡³å‹•æ…‹çˆ¬å–ã€‚

    Args:
        url: è¦çˆ¬å–çš„ç¶²ç«™ URLã€‚

    Returns:
        tuple: (ç¶²é ç´”æ–‡å­—, ç‹€æ…‹ç¢¼)ã€‚
            - æˆåŠŸæ™‚è¿”å› (text, 'OK')
            - éœæ…‹çˆ¬å–ä½†å…§å®¹ç‚ºç©ºæ™‚è¿”å› (None, 'OK_Empty')
            - å‹•æ…‹çˆ¬å–æˆåŠŸæ™‚è¿”å› (text, 'OK_Dynamic')
            - å¤±æ•—æ™‚è¿”å› (None, 'Error_XXX')
    """
    # å˜—è©¦éœæ…‹çˆ¬å–
    # text, status = _fetch_static_content(url)

    text, status = _fetch_static_content(url)
    # å¦‚æœéœæ…‹çˆ¬å–çµæœç‚ºç©ºï¼Œå‰‡å˜—è©¦å‹•æ…‹çˆ¬å–
    if status == 'OK_Empty':
        # print(f"ç¶²é  {url} éœæ…‹å…§å®¹ç‚ºç©ºï¼Œæš«æ™‚è·³é...")
        # return text, status
        print(f"ç¶²é  {url} éœæ…‹å…§å®¹ç‚ºç©ºï¼Œåˆ‡æ›è‡³å‹•æ…‹çˆ¬å–...")
        return _fetch_dynamic_content(url)

    return text, status

def _fetch_static_content(url: str) -> Tuple[Optional[str], str]:
    """
    ä½¿ç”¨ requests çˆ¬å–éœæ…‹ç¶²é å…§å®¹ã€‚
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',
            'Accept-Language': 'zh-TW,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://www.google.com/',
            'Connection': 'keep-alive'
        }
        response = requests.get(url, headers=headers, allow_redirects=False, timeout=10)

        # åœ¨é€™è£¡æª¢æŸ¥ç‹€æ…‹ç¢¼ï¼Œè™•ç†é‡æ–°å°å‘
        if response.status_code == 301 or response.status_code == 302:
            print(f"ç¶²é  {url} ç™¼ç”Ÿé‡æ–°å°å‘ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None, f'Redirect_{response.status_code}'
        # # --- æ–°å¢çš„åµéŒ¯ç¨‹å¼ç¢¼ ---
        # print("--- é–‹å§‹åµæ¸¬ Response ---")
        # print(f"URL: {response.url}")
        # print(f"ç‹€æ…‹ç¢¼: {response.status_code}")
        # print("--- ç¶²é å…§å®¹ (å‰ 500 å­—) ---")
        # print(response.text[:500])  # å°å‡ºç¶²é å…§å®¹çš„å‰ 500 å€‹å­—å…ƒ
        # print("--- åµæ¸¬çµæŸ ---")
        response.raise_for_status()

        soup = BeautifulSoup(response.content, 'html.parser')
        web_text = soup.get_text(separator=' ', strip=True)

        # æª¢æŸ¥é é¢æ˜¯å¦åŒ…å« JavaScript é‡æ–°å°å‘æŒ‡ä»¤
        # if soup.find('script', string=lambda s: 'window.location.href' in s if s else False):
        #     print(f"ç¶²é  {url} åµæ¸¬åˆ° JavaScript é‡æ–°å°å‘")
        #     return None, 'Redirect_JS'

        print(f"ç¶²é  {url} éœæ…‹çˆ¬å–å®Œæˆ...")
        return (web_text, 'OK') if web_text else (None, 'OK_Empty')

    except requests.exceptions.HTTPError as e:
        # å°ˆé–€è™•ç† HTTP éŒ¯èª¤ï¼Œä¾‹å¦‚ 404, 403, 500
        if e.response.status_code == 404:
            return None, 'Error_404' # æ˜ç¢ºæ¨™ç¤º 404
        else:
            return None, f'Error_HTTP_{e.response.status_code}'

    except requests.exceptions.RequestException as e:
        # è™•ç†å…¶ä»–ç¶²è·¯å±¤ç´šçš„éŒ¯èª¤ï¼Œä¾‹å¦‚è¶…æ™‚(Timeout)ã€DNSè§£æå¤±æ•—ç­‰
        print(f"    âŒ éŒ¯èª¤: ç„¡æ³•çˆ¬å–ç¶²é  {url}ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return None, 'Error_Request'
    except Exception as e:
        # å…¶ä»–æœªé æœŸéŒ¯èª¤
        print(f"    âŒ éŒ¯èª¤: çˆ¬å–ç¶²é æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
        return None, 'Error_Unknown'

def _fetch_dynamic_content(url: str) -> Tuple[Optional[str], str]:
    """
    ä½¿ç”¨ Selenium çˆ¬å–å‹•æ…‹ç¶²é å…§å®¹ã€‚
    """
    try:
        chrome_options = Options()
        chrome_options.add_argument('--headless') # å•Ÿç”¨ç„¡é ­æ¨¡å¼ï¼Œè®“ç€è¦½å™¨åœ¨èƒŒæ™¯é‹è¡Œï¼Œä¸é¡¯ç¤ºè¦–çª—
        chrome_options.add_argument('--no-sandbox') # é¿å…åœ¨ Colab ç’°å¢ƒä¸‹å¯èƒ½ç™¼ç”Ÿçš„æ¬Šé™å•é¡Œ
        chrome_options.add_argument('--disable-dev-shm-usage') # è§£æ±º /dev/shm åˆ†å€ç©ºé–“ä¸è¶³çš„å•é¡Œï¼Œé€™åœ¨ Docker æˆ– Colab ä¸­å¾ˆå¸¸è¦‹
        chrome_options.add_argument('--disable-gpu') # ç¦ç”¨ GPU åŠ é€Ÿ
        chrome_options.add_argument('--disable-setuid-sandbox') # è®“ Chrome å¯ä»¥åœ¨ä¸å®‰å…¨çš„ç’°å¢ƒä¸‹åŸ·è¡Œ

        # æ¨¡æ“¬ä¸€å€‹çœŸå¯¦çš„ User-Agentï¼Œé¿å…è¢«ç¶²ç«™åµæ¸¬ç‚ºçˆ¬èŸ²
        chrome_options.add_argument('--user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"')
        # æŒ‡å®š Chrome åŸ·è¡Œæª”è·¯å¾‘ï¼ŒæŒ‡å‘æˆ‘å€‘æ‰‹å‹•å®‰è£çš„ä½ç½®
        chrome_options.binary_location = "/bin/chrome-linux64/chrome"
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)

        driver.get(url)
        # ç­‰å¾…ç¶²é å…§å®¹è¼‰å…¥ï¼Œå¯ä¾æ“šç¶²ç«™ç‰¹æ€§èª¿æ•´æ™‚é–“
        time.sleep(10)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        web_text = soup.get_text(separator=' ', strip=True)

        print(f"ç¶²é  {url} å‹•æ…‹çˆ¬å–å®Œæˆ...")
        return (web_text, 'OK_Dynamic') if web_text else (None, 'OK_Dynamic_Empty')
    except Exception as e:
        print(f"âŒ éŒ¯èª¤: ä½¿ç”¨ Selenium çˆ¬å–ç¶²é æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è¨Šæ¯: {e}")
        return None, 'Error_Selenium'
    finally:
        if 'driver' in locals():
            driver.quit()


def analyze_text_with_gemini(model: genai.GenerativeModel, web_text: str) -> Optional[Dict[str, Any]]:

    """
    ä½¿ç”¨ Gemini åˆ†ææ–‡æœ¬ä¸¦å›å‚³çµæ§‹åŒ–çš„ JSON ç‰¹å¾µã€‚
    Args:
        model: å·²åˆå§‹åŒ–çš„ Gemini æ¨¡å‹ç‰©ä»¶ã€‚
        web_text: å¾ç¶²é çˆ¬å–ä¸‹ä¾†çš„ç´”æ–‡å­—ã€‚
    Returns:
        æˆåŠŸæ™‚è¿”å›åŒ…å«èªæ„ç‰¹å¾µçš„å­—å…¸ï¼Œå¤±æ•—æ™‚è¿”å› Noneã€‚
    """
    prompt_template = f"""
    # Role: Cyber Security Analyst

  You are a senior cybersecurity analyst specializing in phishing detection. Your task is to objectively analyze the provided web page text and determine if it exhibits characteristics of a phishing attempt, strictly based on the content provided.

  Based *only* on the text provided, generate a JSON object containing the following features. You must remain objective and provide assessments based solely on observable evidence within the text.

  - `creates_urgency`: (boolean) Does the text create a sense of urgency, pressure, or a deadline for the user to act quickly?
  - `uses_threats`: (boolean) Does the text contain threats, warnings of account suspension, or other negative consequences if the user doesn't act?
  - `requests_sensitive_info`: (boolean) Does the text explicitly or implicitly ask for login credentials (username, password), financial details (credit card numbers), or personal identification?
  - `offers_unrealistic_rewards`: (boolean) Does the text offer prizes, lottery winnings, or other rewards that seem too good to be true?
  - `has_spelling_grammar_errors`: (boolean) Are there noticeable spelling or grammatical errors that are uncharacteristic of a professional website?
  - `impersonated_brand`: (string) What specific brand or company (e.g., "Facebook", "Google", "ä¸­è¯éƒµæ”¿") is the text trying to impersonate? This judgment must be based *solely* on mentions, logos, or design cues implied by the *text description* provided. If no specific brand is clear from the text, return "N/A".
  - `language_professionalism_score`: (numeric, 0-10) Rate the professionalism and grammatical correctness of the text.
      - 0-2: Severely unprofessional, numerous glaring spelling/grammar errors, unclear language.
      - 3-5: Noticeable errors, somewhat unprofessional, but understandable.
      - 6-8: Mostly professional, minor or infrequent errors.
      - 9-10: Highly professional, no discernible errors, official tone.
      - Only assign scores of 0 or 10 if there is overwhelming, undeniable evidence to support such an extreme assessment. Most cases will fall between 2 and 8.
  - `overall_phishing_likelihood_score`: (numeric, 0-10) Based on ALL textual clues (urgency, threats, info requests, rewards, language errors, impersonation), what is the overall likelihood that this is a phishing page?
      - 0-2: Very low likelihood; text appears legitimate or benign.
      - 3-5: Moderate likelihood; some suspicious elements, but not conclusive.
      - 6-8: High likelihood; strong indicators of phishing.
      - 9-10: Extremely high likelihood; undeniable phishing attempt based on text.
      - Assign scores of 0 or 10 only if the evidence for or against phishing is absolute and unequivocal. Favor scores between 2 and 8 for nuanced cases.
  - `summary_of_intent`: (string) A brief, one-sentence summary explaining the likely intent of the page based on its text.

  ---
  # Web Page Text to Analyze:

  {web_text}

  ---
  IMPORTANT INTERNAL CHECK: Before generating the JSON, review your assessment. Ensure each boolean and score is based *strictly* on the provided `web_text` and adheres to the specified scoring criteria and objectivity requirements. If any part of your answer does not meet these standards, re-evaluate and correct it before outputting. Do not include this check in your final JSON output.

  # JSON Output:
  """

    # --- è‡ªå‹•é‡è©¦æ©Ÿåˆ¶ ---
    max_retries = 3 # æœ€å¤šé‡è©¦ 3 æ¬¡
    base_wait_time = 5 # åŸºç¤ç­‰å¾…æ™‚é–“ 5 ç§’

    for i in range(max_retries):
      try:
          response = model.generate_content(prompt_template)
          json_string = response.text.strip().replace('```json', '').replace('```', '')
          return json.loads(json_string), 'OK'
      except exceptions.ResourceExhausted:
        # 429 éŒ¯èª¤ï¼Œç›´æ¥å›å‚³å¤±æ•—ç‹€æ…‹ï¼Œä¸å†é‡è©¦ (å› ç‚ºé€šå¸¸éœ€è¦ç­‰å¾ˆä¹…)
        print("    âŒ éŒ¯èª¤: æ”¶åˆ° 429 é »ç‡é™åˆ¶éŒ¯èª¤ã€‚æ”¾æ£„æ­¤ç­†è³‡æ–™çš„ Gemini åˆ†æã€‚")
        return None, 'Error_429_RateLimit'
      except exceptions.ServiceUnavailable as e: # å°ˆé–€æ•æ‰ 503 Service Unavailable éŒ¯èª¤
              wait_time = base_wait_time * (2 ** i) # ç­‰å¾…æ™‚é–“ä»¥æŒ‡æ•¸å¢é•· (5s, 10s, 20s)
              print(f"    âš ï¸ è­¦å‘Š: æ”¶åˆ° 503 ä¼ºæœå™¨ä¸å¯ç”¨éŒ¯èª¤ã€‚å°‡åœ¨ {wait_time} ç§’å¾Œé€²è¡Œç¬¬ {i+1}/{max_retries} æ¬¡é‡è©¦...")
              time.sleep(wait_time)
      except Exception as e:
          print(f"    âŒ éŒ¯èª¤: Gemini API åˆ†ææˆ– JSON è§£æå¤±æ•—ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
          return None, 'Error_JSON_Parse'

    print(f"    âŒ éŒ¯èª¤: é‡è©¦ {max_retries} æ¬¡å¾Œä»ç„¶å¤±æ•— (503)ã€‚")
    return None, 'Error_503_Retries_Failed'

def process_dataframe(df_batch: pd.DataFrame, model: genai.GenerativeModel) -> pd.DataFrame:
    """
    éæ­· DataFrameï¼Œå°æ¯å€‹ URL é€²è¡Œåˆ†æä¸¦æ“´å……ç‰¹å¾µã€‚
    Args:
        df: åŸå§‹çš„ DataFrameã€‚
        model: å·²åˆå§‹åŒ–çš„ Gemini æ¨¡å‹ç‰©ä»¶ã€‚
    Returns:
        æ“´å……äº†èªæ„ç‰¹å¾µå¾Œçš„ DataFrameã€‚
    """
    print("\nğŸš€ é–‹å§‹è™•ç† DataFrame ä¸­å°æ‰¹æ¬¡çš„ URL...\n")
    df_processed = df_batch.copy()


    for index, row in df_processed.iterrows():
        print(f"--- æ­£åœ¨è™•ç†ç¬¬ {index + 1}/{len(df_processed)} ç­†è³‡æ–™: {row['url']} ---")

        web_text, fetch_status = safe_process_url(row['url'])

        df_processed.loc[index, 'fetch_status'] = fetch_status

        if not web_text:
            df_processed.loc[index, 'gemini_status'] = 'Skipped_Due_To_Fetch_Error'
            print("    ç¶²é è¢«é‡æ–°å°å‘æˆ–æ˜¯æ–‡æœ¬ç‚ºç©ºã€‚")
            print("    â­ï¸ è·³éæ­¤ç­†è³‡æ–™ã€‚")
            continue

        semantic_features, gemini_status = analyze_text_with_gemini(model, web_text)
        df_processed.loc[index, 'gemini_status'] = gemini_status
        if not semantic_features:
            print("    â­ï¸ è·³éæ­¤ç­†è³‡æ–™ã€‚")
            continue

        print("    âœ… æˆåŠŸå–å¾—ç‰¹å¾µï¼Œæ­£åœ¨æ›´æ–° DataFrame...")
        for key, value in semantic_features.items():
            if key in df_processed.columns:
                df_processed.loc[index, key] = value

        print(f"    â° è™•ç†å®Œæˆï¼Œç­‰å¾… {DELAY_SECONDS} ç§’...\n")
        time.sleep(DELAY_SECONDS)

    return df_processed

def load_data() -> pd.DataFrame:

  uploaded = files.upload()

  for fn in uploaded.keys():
    print('User uploaded file "{name}" with length {length} bytes'.format(
        name=fn, length=len(uploaded[fn])))

  # å°‡ä¸Šå‚³çš„æª”æ¡ˆè®€å–åˆ° pandas DataFrame ä¸­
  # å‡è¨­ä¸Šå‚³çš„æª”æ¡ˆæ˜¯ CSV æ ¼å¼ã€‚å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œæ‚¨å¯èƒ½éœ€è¦èª¿æ•´è®€å–å‡½æ•¸ï¼ˆä¾‹å¦‚ï¼špd.read_excelï¼‰
  file_name = next(iter(uploaded))
  df = pd.read_csv(file_name)

  # é¡¯ç¤º DataFrame çš„å‰ 5 è¡Œ
  print("âœ… è³‡æ–™é›†è¼‰å…¥æˆåŠŸï¼")
  return df

import signal

class TimeoutException(Exception):
    pass

def handler(signum, frame):
    raise TimeoutException()

def safe_process_url(url, max_time=90):
    signal.signal(signal.SIGALRM, handler)
    signal.alarm(max_time)  # è¨­å®šæœ€å¤šè™•ç† max_time ç§’
    try:
        web_text, fetch_status = fetch_webpage_text(url)
        signal.alarm(0)  # æˆåŠŸå°±æ¸…æ‰ alarm
        return web_text, fetch_status
    except TimeoutException:
        print(f"â° URL {url} è¶…é {max_time} ç§’ï¼Œå¼·åˆ¶è·³é")
        return None, 'Error_Connect'
    except Exception as e:
        print(f"âŒ URL {url} è™•ç†å¤±æ•—: {e}")
        return None, 'Error_Unknown'


def main():
    global initial_data
    """
    ä¸»å‡½å¼ï¼Œè² è²¬ä¸²é€£æ•´å€‹è™•ç†æµç¨‹ã€‚
    """
    model = setup_gemini()
    if not model:
        return # å¦‚æœ API è¨­å®šå¤±æ•—ï¼Œå‰‡çµæŸç¨‹å¼

    BATCH_SIZE = 1000

    # --- æ­¥é©Ÿ 1: è¼‰å…¥é€²åº¦ ---
    df = load_data()
    initial_data = df
    if os.path.exists(IN_PROGRESS_FILE):
        print(f"ç™¼ç¾è™•ç†ä¸­æª”æ¡ˆï¼Œå¾ '{IN_PROGRESS_FILE}' è¼‰å…¥é€²åº¦...")
        df = pd.read_csv(IN_PROGRESS_FILE)
    else:
        print(f"æœªç™¼ç¾è™•ç†ä¸­æª”æ¡ˆï¼Œå¾åŸå§‹æª” '{ORIGINAL_DATA_FILE}' é–‹å§‹æ–°ä»»å‹™...")
        try:

            # é å…ˆå»ºç«‹æ–°æ¬„ä½ä¸¦å¡«æ»¿ NaN
            new_columns = [
                'gemini_status', #æ–°å¢çš„ç‹€æ…‹æ¬„ä½
                'fetch_status', # æ–°å¢çš„ç‹€æ…‹æ¬„ä½
                'creates_urgency', 'uses_threats', 'requests_sensitive_info',
                'offers_unrealistic_rewards', 'has_spelling_grammar_errors',
                'impersonated_brand', 'language_professionalism_score',
                'overall_phishing_likelihood_score', 'summary_of_intent'
            ]
            for col in new_columns:
                df[col] = np.nan
        except FileNotFoundError:
            print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ°åŸå§‹è³‡æ–™æª” '{ORIGINAL_DATA_FILE}'ã€‚è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚")
            return

    # --- æ­¥é©Ÿ 2: å°‹æ‰¾æœªå®Œæˆçš„ä»»å‹™ ---
    # ç”¨ 'overall_phishing_likelihood_score' ä½œç‚ºåˆ¤æ–·æ˜¯å¦è™•ç†éçš„æ¨™è¨˜
    unprocessed_mask = df['fetch_status'].isnull()
    unprocessed_df = df[unprocessed_mask]
    # unprocessed_df = df[:1000]
    # unprocessed_df = df[(df['fetch_status'] == 'OK_empty') & (df['gemini_status'] == 'Error_JSON_Parse')].loc[9286:]
    if unprocessed_df.empty:
        print("\nğŸ‰ğŸ‰ğŸ‰ æ­å–œï¼æ‰€æœ‰è³‡æ–™éƒ½å·²è™•ç†å®Œç•¢ï¼ğŸ‰ğŸ‰ğŸ‰")
        return


    # --- æ­¥é©Ÿ 3: é¸å–æœ¬æ¬¡æ‰¹æ¬¡ ---

    batch_to_process = unprocessed_df.head(BATCH_SIZE)
    # print(f"æœ¬æ¬¡å°‡è™•ç† {len(batch_to_process)} ç­†è³‡æ–™ã€‚")
    # start_index = 3690
    # end_index = 3693
    # batch_to_process = df.loc[start_index:end_index +1]

    # --- æ­¥é©Ÿ 4: è™•ç†æ‰¹æ¬¡ ---
    processed_batch = process_dataframe(batch_to_process, model)

    # --- æ­¥é©Ÿ 5: æ›´æ–°èˆ‡å„²å­˜ ---
    # ä½¿ç”¨ .update() å°‡è™•ç†å®Œçš„æ‰¹æ¬¡çš„çµæœï¼Œæ›´æ–°å›åŸå§‹çš„å®Œæ•´ DataFrame ä¸­
    df.update(processed_batch)

    print("="*50)
    print("\nâœ… æ‰€æœ‰è³‡æ–™è™•ç†å®Œç•¢ï¼")
    print("\n--- æœ€çµ‚æ“´å……å¾Œçš„ DataFrame ---")

    display_columns = ['url', 'target'] + [col for col in df.columns if col not in initial_data]
    print(df[display_columns])

    # å»ºè­°ï¼šå°‡æœ€çµ‚çµæœå„²å­˜åˆ°æª”æ¡ˆ
    try:
        df.to_csv(IN_PROGRESS_FILE, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ é€²åº¦å·²æ›´æ–°ä¸¦å„²å­˜è‡³ '{IN_PROGRESS_FILE}'")
        remaining = len(df[df['overall_phishing_likelihood_score'].isnull()])
        print(f"ğŸŸ¢ ç›®å‰å‰©é¤˜ {remaining} ç­†è³‡æ–™å¾…è™•ç†ã€‚")
        num = df[(df['fetch_status'].notna())].shape[0]
        count = df[(df['fetch_status'].notna()) & (df['gemini_status'] != 'OK')].shape[0]
        print(f'"çˆ¬å–éçš„{num}ç­†è³‡æ–™ä¸­ï¼Œ{count}ç­†è³‡æ–™ç„¡æ³•çˆ¬å–åˆ°ç¶²é å…§å®¹ã€‚')
    except Exception as e:
        print(f"\nâŒ å„²å­˜æª”æ¡ˆå¤±æ•—: {e}")


if __name__ == "__main__":
    main()
